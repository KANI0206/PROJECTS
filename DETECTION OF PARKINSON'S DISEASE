# Status representation through Bar Chart
import numpy as np
import pandas as pd
import os, sys
from sklearn.preprocessing import MinMaxScaler
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
df=pd.read_csv('C:\\Users\\DELL\\Downloads\\Parkinsson disease.csv')
df.head()
features=df.loc[:,df.columns!='status'].values[:,1:]
labels=df.loc[:,'status'].values
print(labels[labels==1].shape[0], labels[labels==0].shape[0])
scaler=MinMaxScaler((-1,1))
x=scaler.fit_transform(features)
y=labels
x_train,x_test,y_train,y_test=train_test_split(x, y, test_size=0.2, random_state=7)
model=XGBClassifier()
model.fit(x_train,y_train)
y_pred=model.predict(x_test)
print(accuracy_score(y_test, y_pred)*100)
corr_matrix = df.corr()
fig, ax = plt.subplots(figsize=(30, 30))
ax = sns.heatmap(corr_matrix,
 annot=True,
 linewidths=0.5,
 fmt=".2f",
 cmap="YlGnBu");
bottom, top = ax.get_ylim()
ax.set_ylim(bottom + 0.5, top - 0.5)
df.status.value_counts().plot(kind="bar", color=["yellow", "teal"])
# Representation of Correlation matrix ,Spiral output
import os
import cv2
import numpy as np
from skimage import feature
import random
import matplotlib.pyplot as plt
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
%matplotlib inline
def quantify_image(image):
 features = feature.hog(image, orientations=9,
 pixels_per_cell=(10, 10), cells_per_block=(2, 2),
 transform_sqrt=True, block_norm="L1")
 return feature
def load_split(path):
 # grab the list of images in the input directory, then initialize
 # the list of data (i.e., images) and class labels
 imagePaths = list(paths.list_images(path))
 data = []
 labels = []
 # loop over the image paths
 for imagePath in imagePaths:
 # extract the class label from the filename
 label = imagePath.split(os.path.sep)[-2]
 # load the input image, convert it to grayscale, and resize
 # it to 200x200 pixels, ignoring aspect ratio
 image = cv2.imread(imagePath)
 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
 image = cv2.resize(image, (200, 200))
 # threshold the image such that the drawing appears as white
 # on a black background
 image = cv2.threshold(image, 0, 255,
 cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]
 # quantify the image
 features = quantify_image(image)
 # update the data and labels lists, respectively
 data.append(features)
 labels.append(label)
 return (np.array(data), np.array(labels))
!pip install imutils
from imutils import paths
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import confusion_matrix
def train_models(dataset):
 # initialize the models
 models = {
 "Rf": {
 "classifier": RandomForestClassifier(random_state=1),
 "accuracy": 0,
"sensitivity": 0,
 "specificity": 0,
 },
 "Xgb": {
 "classifier": XGBClassifier(),
 "accuracy": 0,
 "sensitivity": 0,
 "specificity": 0,
 }
 }
 # define the path to the testing and training directories
 path = "C:\\Users\\DELL\\Downloads\\drawings\\" + dataset
 trainingPath = os.path.sep.join([path, "training"])
 testingPath = os.path.sep.join([path, "testing"])
 # load the data
 (trainX, trainY) = load_split(trainingPath)
 (testX, testY) = load_split(testingPath)
 # encode the labels
 le = LabelEncoder()
 trainY = le.fit_transform(trainY)
 testY = le.transform(testY)
 # train each model and calculate its metrics
 for model in models:
 models[model]["classifier"].fit(trainX, trainY)
 predictions = models[model]["classifier"].predict(testX)
 cm = confusion_matrix(testY, predictions).ravel()
 tn, fp, fn, tp = cm
 models[model]["accuracy"] = (tp + tn) / float(cm.sum())
 models[model]["sensitivity"] = tp / float(tp + fn)
 models[model]["specificity"] = tn / float(tn + fp)
 return models
spiralModels = train_models('spiral')
waveModels = train_models('wave')
print("Random Forrest vs XGBoost Classifier\n\n")
for metric in ("accuracy", "sensitivity", "specificity"):
print(f"{metric.capitalize()}: ")
 print("Random Forrest={:.2f}%, XGBoost={:.2f}% \n".format(
 spiralModels['Rf'][metric]*100, spiralModels['Xgb'][metric]*100))
print("Random Forrest vs XGBoost Classifier\n\n")
for metric in ("accuracy", "sensitivity", "specificity"):
 print(f"{metric.capitalize()}: ")
 print("Random Forrest={:.2f}%, XGBoost={:.2f}% \n".format(
 waveModels['Rf'][metric]*100, waveModels['Xgb'][metric]*100))
def test_prediction(model, testingPath):
 # get the list of images
 testingPaths = list(paths.list_images(testingPath))
 output_images = []
 # pick 15 images at random
 for _ in range(15):
 image = cv2.imread(random.choice(testingPaths))
 output = image.copy()
 output = cv2.resize(output, (128, 128))
 # pre-process the image
 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
 image = cv2.resize(image, (200, 200))
 image = cv2.threshold(image, 0, 255,
 cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]
 # quantify the image and make predictions based on the extracted features
 features = quantify_image(image)
 preds = model.predict([features])
 label = "Parkinsons" if preds[0] else "Healthy"
 # draw the colored class label on the output image and add it to
 # the set of output images
 color = (58,228,132) if label == "Healthy" else (255, 0, 0)
 cv2.putText(output, label, (3, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5,
 color, 2)
 output_images.append(output)
 plt.figure(figsize=(20, 20))
 for i in range(len(output_images)):
 plt.subplot(5, 5, i+1)
 plt.imshow(output_images[i])
plt.axis("off")
 plt.show()
testingPath = os.path.sep.join(['C:\\Users\\DELL\\Downloads\\drawings\\spiral', 'testing'])
test_prediction(spiralModels['Rf']['classifier'], testingPath)
testingPath = os.path.sep.join(["C:\\Users\\DELL\\Downloads\\drawings\\wave", "testing"])
test_prediction(waveModels['Rf']['classifier'], testingPath)
